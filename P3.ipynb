{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing some useful packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import keras\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53416"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('MMdriving_log.csv', header = None)\n",
    "data.columns = [\"center_images\",\"left_images\",\"right_images\",\"steering\",\"brake\",\"throttle\",\"speed\"]\n",
    "steering = data['steering'] \n",
    "images = data['center_images']\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.copy(data['center_images'])\n",
    "Y_train = np.copy(data['steering'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 66\n",
    "img_cols = 200\n",
    "ch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_image(imagepath):\n",
    "    oriimage = cv2.imread(imagepath, 1)\n",
    "    # do any preprocessing... resize, reshape, etc. here\n",
    "    newimage = cv2.resize(oriimage, (200, 66))\n",
    "    return newimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Steering angle prediction model\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our image generator.\n",
    "def batchgen(X, Y):\n",
    "    while 1:\n",
    "        for i in range(len(X)):\n",
    "            y = Y[i]\n",
    "            imagepath = X[i]\n",
    "                       \n",
    "            image = load_image(imagepath)\n",
    "            y = np.array([[y]])\n",
    "            image = image.reshape(1, img_rows, img_cols, ch)\n",
    "            yield image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a93aff7f2e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Formula is (image_size - (filter_size+1))/stride, for valid padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(time_len=1):\n",
    "    # input: 80x160 images with 3 channels -> (3, 80, 160) tensors.\n",
    "    row, col, ch = 66, 200, 3  # camera format\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    # this applies 24 convolution filters of size 5x5 each.\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    # Output of above Conv2D is (80-(5+1))/2 = 37 and (160-(5 + 1))/2 = 77\n",
    "    # 24@37x77  Parameters from first conv = 24*5*5*3 = \n",
    "    # depth@convsize*convsize*ch = 1824\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.2))    \n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    # Output of above Conv2D is (37-(5+1))/2 = 15 and (77-(5 + 1))/2 = 35\n",
    "    # 36@16x36  Paramenters from second conv = 24*36*5*5 = 21636\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    # Output of above Conv2D is (16-(5+1))/2 = 5 and (36-(5 + 1))/2 = 15\n",
    "    # 48@5x15  Parameters 24*36*48*5*4\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"same\"))\n",
    "    # Output of above Conv2D is (3-(3+1)) = 1 and (15-(3+ 1))= 10\n",
    "    # 64@1x5  320 neurons\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"same\"))\n",
    "    # Output of above Conv2D is (5-(3+1))/2 = 5 and (15-(3+ 1))/2 = 15\n",
    "    # 64@1x5  320 neurons\n",
    "    model.add(ELU())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Dropout(.5))\n",
    "  \n",
    "    model.compile(optimizer=Adam(), loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53416/53416 [==============================] - 1592s - loss: 367.4448  \n",
      "Epoch 2/5\n",
      "53416/53416 [==============================] - 1673s - loss: 0.0252  \n",
      "Epoch 3/5\n",
      "53416/53416 [==============================] - 1798s - loss: 0.0252  \n",
      "Epoch 4/5\n",
      "53416/53416 [==============================] - 1783s - loss: 0.0252  \n",
      "Epoch 5/5\n",
      "53416/53416 [==============================] - 1716s - loss: 0.0252  \n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(batchgen(X_train, Y_train), samples_per_epoch = 53416, nb_epoch = nb_epoch,\n",
    "                    verbose=1, callbacks=[], validation_data=None,\n",
    "                    class_weight=None, pickle_safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 66, 200, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 33, 100, 24)   1824        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 33, 100, 24)   0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 33, 100, 24)   0           elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 17, 50, 36)    21636       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 17, 50, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 17, 50, 36)    0           elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 9, 25, 48)     43248       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 9, 25, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 9, 25, 48)     0           elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 9, 25, 64)     27712       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 9, 25, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 9, 25, 64)     0           elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 9, 25, 64)     36928       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 9, 25, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 14400)         0           elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 14400)         0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 14400)         0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            460832      elu_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 32)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 32)            0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            330         elu_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 10)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 10)            0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             11          elu_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 592521\n",
      "____________________________________________________________________________________________________\n",
      "Saved model weights and configuration file.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.save_weights(\"model.h5\", True)\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)\n",
    "    \n",
    "print(\"Saved model weights and configuration file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
